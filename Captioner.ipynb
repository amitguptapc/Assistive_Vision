{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Captioner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbnqvP_te2Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.layers.merge import add\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE-UX1YvmZb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 74\n",
        "vocab_size = 5121\n",
        "embedding_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhekGlq3ghTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./drive/My Drive/features/encoded_captions.pkl', 'rb') as f:\n",
        "  train_descriptions = pickle.load(f)\n",
        "with open('./drive/My Drive/features/word2idx.pkl', 'rb') as f:\n",
        "  word2idx = pickle.load(f)\n",
        "with open('./drive/My Drive/features/idx2word.pkl', 'rb') as f:\n",
        "  idx2word = pickle.load(f)\n",
        "with open(\"./drive/My Drive/features/embedding_index.pkl\", 'rb') as f:\n",
        "  embedding_index = pickle.load(f)\n",
        "with open('./drive/My Drive/features/encoded_image_features.pkl', 'rb') as f:\n",
        "  encoded_img = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKde1xTHfL3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(train_descriptions,encoded_img,word2idx,max_len,batch_size):\n",
        "    X1,X2,Y = [],[],[]\n",
        "    n = 0\n",
        "    while True:\n",
        "        for key,cap_list in train_descriptions.items():\n",
        "            n += 1\n",
        "            img = encoded_img[key]\n",
        "            for cap in cap_list:\n",
        "                seq = [word2idx[word] for word in cap.split() if word in word2idx]\n",
        "                for i in range(1,len(seq)):\n",
        "                    xi = seq[0:i]\n",
        "                    yi = seq[i]\n",
        "                    xi = pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n",
        "                    yi = to_categorical([yi],num_classes=vocab_size)[0]\n",
        "                    X1.append(img)\n",
        "                    X2.append(xi)\n",
        "                    Y.append(yi)\n",
        "                if n == batch_size:\n",
        "                    yield [[np.array(X1),np.array(X2)],np.array(Y)]\n",
        "                    X1,X2,Y = [],[],[]\n",
        "                    n = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtckGtAHhPmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding_matrix():\n",
        "  matrix = np.zeros((vocab_size,embedding_dim))\n",
        "  for word,idx in word2idx.items():\n",
        "    embed_vector = embedding_index.get(word)\n",
        "    if embed_vector is not None:\n",
        "      matrix[idx] = embed_vector\n",
        "  return matrix\n",
        "  \n",
        "embedding_matrix = get_embedding_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsHlj7O1f3ae",
        "colab_type": "code",
        "outputId": "8b2a949a-836f-4ee3-a970-b558bf825ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# Image Features as Input\n",
        "inp_img = Input(shape=(2048,))\n",
        "inp_img1 = Dropout(0.03)(inp_img)\n",
        "inp_img2 = Dense(256,activation='relu')(inp_img1)\n",
        "# Captions as Input\n",
        "inp_cap = Input(shape=(max_len,))\n",
        "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(inp_cap)\n",
        "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
        "inp_cap3 = LSTM(256)(inp_cap2)\n",
        "# Combined Model\n",
        "decoder1 = add([inp_img2,inp_cap3])\n",
        "decoder2 = Dense(256,activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
        "model = Model(inputs=[inp_img,inp_cap],outputs=outputs)\n",
        "# Initializing The Embedding Layer\n",
        "model.layers[2].set_weights([embedding_matrix])\n",
        "model.layers[2].trainable = False\n",
        "# Compiling The Model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 74)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 2048)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 74, 50)       256050      input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 2048)         0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 74, 50)       0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          524544      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 256)          314368      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256)          0           dense_10[0][0]                   \n",
            "                                                                 lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 256)          65792       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 5121)         1316097     dense_11[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,476,851\n",
            "Trainable params: 2,220,801\n",
            "Non-trainable params: 256,050\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACyYY9D1gABU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 3\n",
        "steps = len(train_descriptions)//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhQWNZobjBOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir drive/'My Drive'/model_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EA_Blvqhk_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions,encoded_img,word2idx,max_len,batch_size)\n",
        "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
        "    model.save('./drive/My Drive/model_weights/model_'+str(i)+'.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8eL_RX-hnna",
        "colab_type": "code",
        "outputId": "f91a1148-15e1-4948-8df2-094b856eebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1697s 160ms/step - loss: 4.2732\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1703s 161ms/step - loss: 3.7688\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1702s 161ms/step - loss: 3.6483\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1726s 163ms/step - loss: 3.5915\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1708s 161ms/step - loss: 3.5609\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1655s 156ms/step - loss: 3.5419\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1667s 157ms/step - loss: 3.5293\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1650s 156ms/step - loss: 3.5196\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1609s 152ms/step - loss: 3.5161\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1607s 152ms/step - loss: 3.5126\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1609s 152ms/step - loss: 3.5101\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1599s 151ms/step - loss: 3.5097\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1596s 151ms/step - loss: 3.5093\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1597s 151ms/step - loss: 3.5100\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1594s 151ms/step - loss: 3.5096\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1604s 151ms/step - loss: 3.5128\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1601s 151ms/step - loss: 3.5136\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1692s 160ms/step - loss: 3.5153\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1726s 163ms/step - loss: 3.5169\n",
            "Epoch 1/1\n",
            "10594/10594 [==============================] - 1747s 165ms/step - loss: 3.5195\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}