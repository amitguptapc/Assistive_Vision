{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbnqvP_te2Bu"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.layers.merge import add\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iE-UX1YvmZb5"
   },
   "outputs": [],
   "source": [
    "max_len = 74\n",
    "vocab_size = 5121\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhekGlq3ghTy"
   },
   "outputs": [],
   "source": [
    "with open('./drive/My Drive/features/encoded_captions.pkl', 'rb') as f:\n",
    "  train_descriptions = pickle.load(f)\n",
    "with open('./drive/My Drive/features/word2idx.pkl', 'rb') as f:\n",
    "  word2idx = pickle.load(f)\n",
    "with open('./drive/My Drive/features/idx2word.pkl', 'rb') as f:\n",
    "  idx2word = pickle.load(f)\n",
    "with open(\"./drive/My Drive/features/embedding_index.pkl\", 'rb') as f:\n",
    "  embedding_index = pickle.load(f)\n",
    "with open('./drive/My Drive/features/encoded_image_features.pkl', 'rb') as f:\n",
    "  encoded_img = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKde1xTHfL3u"
   },
   "outputs": [],
   "source": [
    "def data_generator(train_descriptions,encoded_img,word2idx,max_len,batch_size):\n",
    "    X1,X2,Y = [],[],[]\n",
    "    n = 0\n",
    "    while True:\n",
    "        for key,cap_list in train_descriptions.items():\n",
    "            n += 1\n",
    "            img = encoded_img[key]\n",
    "            for cap in cap_list:\n",
    "                seq = [word2idx[word] for word in cap.split() if word in word2idx]\n",
    "                for i in range(1,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "                    xi = pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n",
    "                    yi = to_categorical([yi],num_classes=vocab_size)[0]\n",
    "                    X1.append(img)\n",
    "                    X2.append(xi)\n",
    "                    Y.append(yi)\n",
    "                if n == batch_size:\n",
    "                    yield [[np.array(X1),np.array(X2)],np.array(Y)]\n",
    "                    X1,X2,Y = [],[],[]\n",
    "                    n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtckGtAHhPmt"
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "  matrix = np.zeros((vocab_size,embedding_dim))\n",
    "  for word,idx in word2idx.items():\n",
    "    embed_vector = embedding_index.get(word)\n",
    "    if embed_vector is not None:\n",
    "      matrix[idx] = embed_vector\n",
    "  return matrix\n",
    "  \n",
    "embedding_matrix = get_embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "WsHlj7O1f3ae",
    "outputId": "6cbfc5d9-1bc1-4c15-8ee3-a6d535044501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 74)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 74, 50)       256050      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 74, 50)       0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          524544      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          314368      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           dense_7[0][0]                    \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 5121)         1316097     dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,476,851\n",
      "Trainable params: 2,220,801\n",
      "Non-trainable params: 256,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Image Features as Input\n",
    "inp_img = Input(shape=(2048,))\n",
    "inp_img1 = Dropout(0.03)(inp_img)\n",
    "inp_img2 = Dense(256,activation='relu')(inp_img1)\n",
    "# Captions as Input\n",
    "inp_cap = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(inp_cap)\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)\n",
    "# Combined Model\n",
    "decoder1 = add([inp_img2,inp_cap3])\n",
    "decoder2 = Dense(256,activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
    "model = Model(inputs=[inp_img,inp_cap],outputs=outputs)\n",
    "# Initializing The Embedding Layer\n",
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False\n",
    "# Compiling The Model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACyYY9D1gABU"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 3\n",
    "steps = len(train_descriptions)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhQWNZobjBOy"
   },
   "outputs": [],
   "source": [
    "!mkdir model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EA_Blvqhk_Y"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions,encoded_img,word2idx,max_len,batch_size)\n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "    if i%5==0:\n",
    "      model.save('./model_weights/model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "F8eL_RX-hnna",
    "outputId": "f86af8f3-b0e1-4db3-d979-aa288dcc1425"
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Captioner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
